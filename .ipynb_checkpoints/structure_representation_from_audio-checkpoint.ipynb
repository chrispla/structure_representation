{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Representation Computation from Audio Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Library importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Data Processing\n",
    "import sklearn.cluster\n",
    "\n",
    "#Audio\n",
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "#System\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Loading audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose directory containing audiofiles\n",
    "directory = '../../Music'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-de5edf2526a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_filepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.aif'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.mp3'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#Read all paths in specified directory\n",
    "all_filepaths = []\n",
    "all_names= []\n",
    "for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if (('.wav' in name) or ('.aif' in name) or ('.mp3' in name)):\n",
    "                filepath = os.path.join(root, name)\n",
    "                all_filepaths.append(filepath)\n",
    "                all_names.append(name)\n",
    "\n",
    "#Dictionary containing all batches of matrices as described by pipeline documentation in a linearized, sequential format\n",
    "X = {}\n",
    "\n",
    "#Load all audiofiles and store in array\n",
    "all_audio = []\n",
    "for i in range(len(all_filepaths)):\n",
    "    y, sr = librosa.load(filepath, sr=22050, mono=True)\n",
    "    all_audio.append((y, sr))\n",
    "    sys.stdout.write(\"\\rLoaded %i/%s pieces.\" % ((i+1), str(len(all_filepaths))))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "X[\"audio\"] = all_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Self Similarity for Repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Single-Feature Self Similarity Matrix (no feature fusion on this script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed spectral representations for 8/8 pieces."
     ]
    }
   ],
   "source": [
    "#Pipeline of primary features to use to compute self similarity\n",
    "#{stft, log_power_CQT, perceptually_weighted_CQT, mel_spectrogram}\n",
    "\n",
    "all_stft = []\n",
    "all_logCQT = []\n",
    "all_perCQT = []\n",
    "all_melspec = []\n",
    "\n",
    "for filepath in range(len(all_filepaths)):\n",
    "    \n",
    "    #STFT\n",
    "    stft = librosa.stft(y=all_audio[filepath][0])\n",
    "    all_stft.append(stft)\n",
    "\n",
    "    #Log-power Constant-Q Transform\n",
    "    bins_per_oct = 12*3\n",
    "    n_oct = 7\n",
    "    CQT = librosa.cqt(y=all_audio[filepath][0], sr=all_audio[filepath][1], bins_per_octave=bins_per_oct, n_bins=n_oct*bins_per_oct)\n",
    "    all_logCQT.append(librosa.amplitude_to_db(CQT))\n",
    "\n",
    "    #Perceptually-weighted Constant-Q Transform\n",
    "    freqs = librosa.cqt_frequencies(CQT.shape[0], fmin=librosa.note_to_hz('A1'))\n",
    "    all_perCQT.append(librosa.perceptual_weighting(np.abs(CQT)**2, freqs))\n",
    "\n",
    "    #Mel-scaled Spectrogram\n",
    "    all_melspec.append(librosa.feature.melspectrogram(S=np.abs(stft)**2, sr=all_audio[filepath][1]))\n",
    "\n",
    "    sys.stdout.write(\"\\rComputed spectral representations for %i/%s pieces.\" % ((filepath+1), str(len(all_filepaths))))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "spectral_rep = {\"stft\":all_stft, \"logCQT\":all_logCQT, \"perCQT\":all_perCQT, \"melspec\":all_melspec}\n",
    "X[\"spectral_rep\"]=spectral_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-22-2e80232896fd>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-2e80232896fd>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    # plt.tight_layout()\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#Plotting\n",
    "fig, axs = plt.subplots(nrows=len(all_filepaths), ncols=4)\n",
    "for i in range(len(all_filepaths)):\n",
    "    for j in range(4):\n",
    "        axs[i, j].matshow(all_spectral_rep[i][j]])\n",
    "        axs[i, j].set_title(all_names[i])\n",
    "    # plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select one dimensionality reduction method out of {none, beat-synchronization, 2d-interpolation}\n",
    "dim_reduction = 'beat-synchronization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Srep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-547ccab72107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim_reduction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'beat-synchronization'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mspec_rep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSrep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mSrep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspec_rep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_spectral_representations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspec_rep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Srep' is not defined"
     ]
    }
   ],
   "source": [
    "#Replace all spectral representations with their dimensionality reduced version\n",
    "for audiofile in range(len(all_filepaths)):\n",
    "    tempo, beats = librosa.beat.beat_track(y=all_audio[audiofile][0], sr=all_audio[audiofile][1], trim=False)\n",
    "\n",
    "    if dim_reduction=='none':\n",
    "        break\n",
    "    if dim_reduction=='beat-synchronization':\n",
    "        for spec_rep in range(len(Srep[audiofile])):\n",
    "            Srep[audiofile][spec_rep] = librosa.util.sync(all_spectral_representations[audiofile][spec_rep], beats, aggregate=np.median)\n",
    "\n",
    "    if dim_reduction=='2d_interpolation': #NEEDS TO BE EVALUATED (is this working as expected, do other methods of downsampling make more sense?)\n",
    "        for spec_rep in range(len(Srep[audiofile])):\n",
    "            #Compute interpolation function\n",
    "            Xindex = np.linspace(0, 1, num=Srep[audiofile][spec_rep].shape[0])\n",
    "            Yindex = np.linspace(0, 1, num=Srep[audiofile][spec_rep].shape[1])\n",
    "            f = interp2d(Xindex, Yindex, num=Srep[audiofile][spec_rep].flatten(), kind='linear')\n",
    "            #Generate new ranges\n",
    "            Xindex_ds = np.linspace(0, 1, num=Srep[audiofile][spec_rep].shape[0]/50)\n",
    "            Yindex_ds = np.linspace(0, 1, num=Srep[audiofile][spec_rep].shape[1]/50)\n",
    "            #Resample\n",
    "            Srep[audiofile][spec_rep] = np.reshape(f(Xindex_ds, Yindex_ds), (shape[0]/50, shape[1]/50))\n",
    "    sys.stdout.write(\"\\rDownlsampled %i/%s pieces.\" % ((audiofile+1), str(len(all_filepaths))))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Short-term History Embedding of spectral representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose number of lag steps\n",
    "n_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cstack = librosa.feature.stack_memory(Csync, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Weighted Recurrence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Timelag filter / Short-term History Embedding(?) / Windowed Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
