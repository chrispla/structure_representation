{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Representation Computation from Audio Input\n",
    "### Comparing choice of spectral representation for the construction of the repetition similarity graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Library importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.interpolate import interp2d\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#Data Processing\n",
    "import sklearn.cluster\n",
    "\n",
    "#Audio\n",
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "#System\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Pickling\n",
    "import dill"
   ]
  },
  {
   "source": [
    "## > Serialization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.dump_session('../../dills/fixyou_spectral.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.load_session('../../dills/fixyou_spectral.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Loading audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose directory containing audiofiles\n",
    "directory = '../../my_covers/Chopin_Mazurka'\n",
    "\n",
    "#Read all paths in specified directory\n",
    "all_filepaths = []\n",
    "all_names = []\n",
    "all_live = []\n",
    "all_covers= []\n",
    "for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if (('.wav' in name) or ('.aif' in name) or ('.mp3' in name)):\n",
    "                all_names.append(name)\n",
    "                filepath = os.path.join(root, name)\n",
    "                all_filepaths.append(filepath)\n",
    "                if ('Live' in name):\n",
    "                    all_live.append(filepath)\n",
    "                elif ('Covers' in name):\n",
    "                    all_covers.append(filepath)\n",
    "    \n",
    "\n",
    "#Dictionary containing all batches of matrices as described by pipeline documentation in a linearized, sequential format\n",
    "X = {}\n",
    "\n",
    "#Load all audiofiles and store in array\n",
    "all_audio = []\n",
    "file_no = len(all_filepaths)\n",
    "for f in range(file_no):\n",
    "    y, sr = librosa.load(all_filepaths[f], sr=22050, mono=True)\n",
    "    all_audio.append((y, sr))\n",
    "    sys.stdout.write(\"\\rLoaded %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "X[\"audio\"] = all_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Self Similarity for Repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Single-Feature Self Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline of primary features to use to compute self similarity\n",
    "#{stft, log_power_CQT, perceptually_weighted_CQT, mel_spectrogram}\n",
    "\n",
    "all_stft = []\n",
    "all_logCQT = []\n",
    "all_chroma = []\n",
    "\n",
    "for f in range(file_no):\n",
    "    \n",
    "    #STFT\n",
    "    stft = librosa.stft(y=X[\"audio\"][f][0])\n",
    "    stft_db = librosa.amplitude_to_db(stft)\n",
    "    all_stft.append(stft_db)\n",
    "\n",
    "    #Log-power Constant-Q Transform\n",
    "    bins_per_oct = 12*3\n",
    "    n_oct = 7\n",
    "    CQT = librosa.cqt(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1], bins_per_octave=bins_per_oct, n_bins=n_oct*bins_per_oct)\n",
    "    all_logCQT.append(librosa.amplitude_to_db(CQT))\n",
    "\n",
    "    #Chroma\n",
    "    chromagram = librosa.feature.chroma_stft(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1])\n",
    "    all_chroma.append(chromagram)\n",
    "\n",
    "    sys.stdout.write(\"\\rComputed spectral representations for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "spectral_rep = {\"stft\":all_stft, \"logCQT\":all_logCQT, \"chroma\":all_chroma}\n",
    "X[\"spectral_rep\"]=spectral_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=file_no, ncols=3, figsize=(20,20))\n",
    "for i in range(file_no):\n",
    "    librosa.display.specshow(X[\"spectral_rep\"][\"stft\"][i], ax=ax[i,0], y_axis='hz')\n",
    "    ax[i, 0].set(title=all_names[i] + ' - STFT')\n",
    "    librosa.display.specshow(X[\"spectral_rep\"][\"logCQT\"][i], ax=ax[i,1], y_axis='cqt_hz', bins_per_octave=bins_per_oct)\n",
    "    ax[i, 1].set(title=all_names[i] + ' - logCQT')\n",
    "    librosa.display.specshow(X[\"spectral_rep\"][\"chroma\"][i], ax=ax[i,2], y_axis='cqt_hz', bins_per_octave=bins_per_oct)\n",
    "    ax[i, 2].set(title=all_names[i] + ' - chroma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Beat Synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"reduced_spectral_rep\"] = {\"stft_beat\":[], \"logCQT_beat\":[], \"chroma_beat\":[]}\n",
    "\n",
    "for f in range(file_no):\n",
    "\n",
    "    #Beat-synchronization\n",
    "    tempo, beats = librosa.beat.beat_track(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1], trim=False)\n",
    "    for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "        X[\"reduced_spectral_rep\"][rep+\"_beat\"].append(librosa.util.sync(X[\"spectral_rep\"][rep][f], beats, aggregate=np.median))\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Short-term History Embedding of spectral representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 4\n",
    "X[\"stacked_spectral_rep\"] = {\"stacked_stft_beat\":[], \"stacked_logCQT_beat\":[], \"stacked_chroma_beat\":[]}\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft_beat\", \"logCQT_beat\", \"chroma_beat\"]:\n",
    "        X[\"stacked_spectral_rep\"][\"stacked_\"+rep].append(librosa.feature.stack_memory(X[\"reduced_spectral_rep\"][rep][f], steps))\n",
    "    \n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Weighted Recurrence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_no = 3\n",
    "X[\"ssm\"] = {\"ssm_s_stft_beat\":[], \"ssm_s_logCQT_beat\":[], \"ssm_s_chroma_beat\":[]}\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft_beat\", \"logCQT_beat\", \"chroma_beat\"]: \n",
    "        X[\"ssm\"][\"ssm_s_\"+rep].append(librosa.segment.recurrence_matrix(X[\"stacked_spectral_rep\"][\"stacked_\"+rep][f], width=knn_no, mode='affinity', sym=True))\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Timelag filter & Path enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"f_ssm\"] = {\"f_ssm_s_stft_beat\":[], \"f_ssm_s_logCQT_beat\":[], \"f_ssm_s_chroma_beat\":[]}\n",
    "df = librosa.segment.timelag_filter(scipy.ndimage.median_filter)\n",
    "\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft_beat\", \"logCQT_beat\", \"chroma_beat\"]: \n",
    "        X[\"f_ssm\"][\"f_ssm_s_\"+rep].append(librosa.segment.path_enhance(df(X[\"ssm\"][\"ssm_s_\"+rep][f], size=(1, 7)), 15))\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Self Similarity for local connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"mfcc\"]=[]\n",
    "for f in range(file_no):\n",
    "    X[\"mfcc\"].append(librosa.feature.mfcc(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1]))\n",
    "\n",
    "    sys.stdout.write(\"\\rComputed %i/%s MFCCs.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"reduced_mfcc\"]={\"mfcc_beat\":[]}\n",
    "\n",
    "for f in range(file_no):\n",
    "    #Beat-synchronization\n",
    "    tempo, beats = librosa.beat.beat_track(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1], trim=False)\n",
    "    X[\"reduced_mfcc\"][\"mfcc_beat\"].append(librosa.util.sync(X[\"mfcc\"][f], beats))\n",
    "\n",
    "    sys.stdout.write(\"\\rDownlsampled %i/%s MFCCs.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Similarity Sequence Matrix (Gaussian Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"S_loc\"]={\"S_loc_mfcc_beat\":[]}\n",
    "\n",
    "for f in range(file_no):\n",
    "    path_distance = np.sum(np.diff(X[\"reduced_mfcc\"][\"mfcc_beat\"][f], axis=1)**2, axis=0)\n",
    "    sigma = np.median(path_distance)\n",
    "    path_sim = np.exp(-path_distance / sigma)\n",
    "    X[\"S_loc\"][\"S_loc_mfcc_beat\"].append(np.diag(path_sim, k=1) + np.diag(path_sim, k=-1))\n",
    "\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Balanced Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"A\"]={\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "    for f in range(file_no):\n",
    "        S_loc = X[\"S_loc\"][\"S_loc_mfcc_beat\"][f]\n",
    "        S_rep = X[\"f_ssm\"][\"f_ssm_s_\"+rep+\"_beat\"][f]\n",
    "        deg_loc = np.sum(S_loc, axis=1)          \n",
    "        deg_rep = np.sum(S_rep, axis=1)\n",
    "        mu = deg_loc.dot(deg_loc + deg_rep) / np.sum((deg_loc + deg_rep)**2)\n",
    "        A = mu * S_rep + (1 - mu) * S_loc\n",
    "        X[\"A\"][rep].append(A)\n",
    "        sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"A_d\"]={\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "        X[\"A_d\"][rep].append(cv2.resize(X[\"A\"][rep][f], (128,128)))\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"Lsym\"] = {\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "X[\"Lsym_d\"] = {\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "    for f in range(file_no):\n",
    "        X[\"Lsym\"][rep].append(scipy.sparse.csgraph.laplacian(X[\"A\"][rep][f], normed=True))\n",
    "        X[\"Lsym_d\"][rep].append(scipy.sparse.csgraph.laplacian(X[\"A_d\"][rep][f], normed=True))\n",
    "        \n",
    "        sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Eigendecomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"D\"] = {\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "X[\"D_d\"] = {\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "\n",
    "kmin = 2\n",
    "kmax = 10\n",
    "\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "        #eigendecomposition\n",
    "        evals, evecs = scipy.linalg.eigh(X[\"Lsym\"][rep][f])\n",
    "        #eigenvector filtering\n",
    "        evecs = scipy.ndimage.median_filter(evecs, size=(9, 1))\n",
    "        #normalization\n",
    "        Cnorm = np.cumsum(evecs**2, axis=1)**0.5\n",
    "        #create set of approximations\n",
    "        dist_set = []\n",
    "        for k in range(kmin, kmax):\n",
    "            Xs = evecs[:, :k] / Cnorm[:, k-1:k]\n",
    "            #distance vector to matrix\n",
    "            distance = scipy.spatial.distance.squareform(scipy.spatial.distance.pdist(Xs, metric='euclidean'))\n",
    "            dist_set.append(distance)\n",
    "        X[\"D\"][rep].append(dist_set)\n",
    "\n",
    "        #eigendecomposition\n",
    "        evals, evecs = scipy.linalg.eigh(X[\"Lsym_d\"][rep][f])\n",
    "        #eigenvector filtering\n",
    "        evecs = scipy.ndimage.median_filter(evecs, size=(9, 1))\n",
    "        #normalization\n",
    "        Cnorm = np.cumsum(evecs**2, axis=1)**0.5\n",
    "        #create set of approximations\n",
    "        dist_set = []\n",
    "        for k in range(kmin, kmax):\n",
    "            Xs = evecs[:, :k] / Cnorm[:, k-1:k]\n",
    "            #distance vector to matrix\n",
    "            distance = scipy.spatial.distance.squareform(scipy.spatial.distance.pdist(Xs, metric='euclidean'))\n",
    "            dist_set.append(distance)\n",
    "        X[\"D_d\"][rep].append(dist_set)\n",
    "\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Plotting eigenvector distances"
   ]
  },
  {
   "source": [
    "### >>> STFT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D\"][\"stft\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### >>> logCQT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D\"][\"logCQT\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### >>> Chroma"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D\"][\"chroma\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### STFT Downsampled"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D_d\"][\"stft\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### >>> logCQT Downsampled"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D_d\"][\"logCQT\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### >>> Chroma Downsampled"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D_d\"][\"chroma\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}