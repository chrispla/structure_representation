{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Representation Computation from Audio Input\n",
    "### Comparing choice of spectral representation for the construction of the repetition similarity graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Library importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.interpolate import interp2d\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#Data Processing\n",
    "import sklearn.cluster\n",
    "\n",
    "#Audio\n",
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "#System\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Pickling\n",
    "import dill"
   ]
  },
  {
   "source": [
    "## > Serialization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.dump_session('../../dills/fixyou_spectral.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.load_session('../../dills/fixyou_spectral.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Loading audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1147fa035bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mfile_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_filepaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_filepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mall_audio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\rLoaded %i/%s pieces.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/resampy/core.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mresample_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Choose directory containing audiofiles\n",
    "directory = '../../my_covers/'\n",
    "\n",
    "#Read all paths in specified directory\n",
    "all_filepaths = []\n",
    "all_names = []\n",
    "all_live = []\n",
    "all_covers= []\n",
    "for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if (('.wav' in name) or ('.aif' in name) or ('.mp3' in name)):\n",
    "                all_names.append(name)\n",
    "                filepath = os.path.join(root, name)\n",
    "                all_filepaths.append(filepath)\n",
    "                if ('Live' in name):\n",
    "                    all_live.append(filepath)\n",
    "                elif ('Covers' in name):\n",
    "                    all_covers.append(filepath)\n",
    "    \n",
    "\n",
    "#Dictionary containing all batches of matrices as described by pipeline documentation in a linearized, sequential format\n",
    "X = {}\n",
    "\n",
    "#Load all audiofiles and store in array\n",
    "all_audio = []\n",
    "file_no = len(all_filepaths)\n",
    "for f in range(file_no):\n",
    "    y, sr = librosa.load(all_filepaths[f], sr=22050, mono=True)\n",
    "    all_audio.append((y, sr))\n",
    "    sys.stdout.write(\"\\rLoaded %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "X[\"audio\"] = all_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Self Similarity for Repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Single-Feature Self Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline of primary features to use to compute self similarity\n",
    "#{stft, log_power_CQT, perceptually_weighted_CQT, mel_spectrogram}\n",
    "\n",
    "all_stft = []\n",
    "all_logCQT = []\n",
    "all_chroma = []\n",
    "\n",
    "for f in range(file_no):\n",
    "    \n",
    "    #STFT\n",
    "    stft = librosa.stft(y=X[\"audio\"][f][0])\n",
    "    stft_db = librosa.amplitude_to_db(stft)\n",
    "    all_stft.append(stft_db)\n",
    "\n",
    "    #Log-power Constant-Q Transform\n",
    "    bins_per_oct = 12*3\n",
    "    n_oct = 7\n",
    "    CQT = librosa.cqt(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1], bins_per_octave=bins_per_oct, n_bins=n_oct*bins_per_oct)\n",
    "    all_logCQT.append(librosa.amplitude_to_db(CQT))\n",
    "\n",
    "    #Chroma\n",
    "    chromagram = librosa.feature.chroma_stft(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1])\n",
    "    all_chroma.append(chromagram)\n",
    "\n",
    "    sys.stdout.write(\"\\rComputed spectral representations for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "spectral_rep = {\"stft\":all_stft, \"logCQT\":all_logCQT, \"chroma\":all_chroma}\n",
    "X[\"spectral_rep\"]=spectral_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=file_no, ncols=3, figsize=(20,20))\n",
    "for i in range(file_no):\n",
    "    librosa.display.specshow(X[\"spectral_rep\"][\"stft\"][i], ax=ax[i,0], y_axis='hz')\n",
    "    ax[i, 0].set(title=all_names[i] + ' - STFT')\n",
    "    librosa.display.specshow(X[\"spectral_rep\"][\"logCQT\"][i], ax=ax[i,1], y_axis='cqt_hz', bins_per_octave=bins_per_oct)\n",
    "    ax[i, 1].set(title=all_names[i] + ' - logCQT')\n",
    "    librosa.display.specshow(X[\"spectral_rep\"][\"chroma\"][i], ax=ax[i,2], y_axis='cqt_hz', bins_per_octave=bins_per_oct)\n",
    "    ax[i, 2].set(title=all_names[i] + ' - chroma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Beat Synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"reduced_spectral_rep\"] = {\"stft_beat\":[], \"logCQT_beat\":[], \"chroma_beat\":[]}\n",
    "\n",
    "for f in range(file_no):\n",
    "\n",
    "    #Beat-synchronization\n",
    "    tempo, beats = librosa.beat.beat_track(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1], trim=False)\n",
    "    for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "        X[\"reduced_spectral_rep\"][rep+\"_beat\"].append(librosa.util.sync(X[\"spectral_rep\"][rep][f], beats, aggregate=np.median))\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Short-term History Embedding of spectral representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 4\n",
    "X[\"stacked_spectral_rep\"] = {\"stacked_stft_beat\":[], \"stacked_logCQT_beat\":[], \"stacked_chroma_beat\":[]}\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft_beat\", \"logCQT_beat\", \"chroma_beat\"]:\n",
    "        X[\"stacked_spectral_rep\"][\"stacked_\"+rep].append(librosa.feature.stack_memory(X[\"reduced_spectral_rep\"][rep][f], steps))\n",
    "    \n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Weighted Recurrence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_no = 3\n",
    "X[\"ssm\"] = {\"ssm_s_stft_beat\":[], \"ssm_s_logCQT_beat\":[], \"ssm_s_chroma_beat\":[]}\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft_beat\", \"logCQT_beat\", \"chroma_beat\"]: \n",
    "        X[\"ssm\"][\"ssm_s_\"+rep].append(librosa.segment.recurrence_matrix(X[\"stacked_spectral_rep\"][\"stacked_\"+rep][f], width=knn_no, mode='affinity', sym=True))\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Timelag filter & Path enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"f_ssm\"] = {\"f_ssm_s_stft_beat\":[], \"f_ssm_s_logCQT_beat\":[], \"f_ssm_s_chroma_beat\":[]}\n",
    "df = librosa.segment.timelag_filter(scipy.ndimage.median_filter)\n",
    "\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft_beat\", \"logCQT_beat\", \"chroma_beat\"]: \n",
    "        X[\"f_ssm\"][\"f_ssm_s_\"+rep].append(librosa.segment.path_enhance(df(X[\"ssm\"][\"ssm_s_\"+rep][f], size=(1, 7)), 15))\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Self Similarity for local connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"mfcc\"]=[]\n",
    "for f in range(file_no):\n",
    "    X[\"mfcc\"].append(librosa.feature.mfcc(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1]))\n",
    "\n",
    "    sys.stdout.write(\"\\rComputed %i/%s MFCCs.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"reduced_mfcc\"]={\"mfcc_beat\":[]}\n",
    "\n",
    "for f in range(file_no):\n",
    "    #Beat-synchronization\n",
    "    tempo, beats = librosa.beat.beat_track(y=X[\"audio\"][f][0], sr=X[\"audio\"][f][1], trim=False)\n",
    "    X[\"reduced_mfcc\"][\"mfcc_beat\"].append(librosa.util.sync(X[\"mfcc\"][f], beats))\n",
    "\n",
    "    sys.stdout.write(\"\\rDownlsampled %i/%s MFCCs.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Similarity Sequence Matrix (Gaussian Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"S_loc\"]={\"S_loc_mfcc_beat\":[]}\n",
    "\n",
    "for f in range(file_no):\n",
    "    path_distance = np.sum(np.diff(X[\"reduced_mfcc\"][\"mfcc_beat\"][f], axis=1)**2, axis=0)\n",
    "    sigma = np.median(path_distance)\n",
    "    path_sim = np.exp(-path_distance / sigma)\n",
    "    X[\"S_loc\"][\"S_loc_mfcc_beat\"].append(np.diag(path_sim, k=1) + np.diag(path_sim, k=-1))\n",
    "\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Balanced Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"A\"]={\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "    for f in range(file_no):\n",
    "        S_loc = X[\"S_loc\"][\"S_loc_mfcc_beat\"][f]\n",
    "        S_rep = X[\"f_ssm\"][\"f_ssm_s_\"+rep+\"_beat\"][f]\n",
    "        deg_loc = np.sum(S_loc, axis=1)          \n",
    "        deg_rep = np.sum(S_rep, axis=1)\n",
    "        mu = deg_loc.dot(deg_loc + deg_rep) / np.sum((deg_loc + deg_rep)**2)\n",
    "        A = mu * S_rep + (1 - mu) * S_loc\n",
    "        X[\"A\"][rep].append(A)\n",
    "        sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"A_d\"]={\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "        X[\"A_d\"][rep].append(cv2.resize(X[\"A\"][rep][f], (128,128)))\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"Lsym\"] = {\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "X[\"Lsym_d\"] = {\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "    for f in range(file_no):\n",
    "        X[\"Lsym\"][rep].append(scipy.sparse.csgraph.laplacian(X[\"A\"][rep][f], normed=True))\n",
    "        X[\"Lsym_d\"][rep].append(scipy.sparse.csgraph.laplacian(X[\"A_d\"][rep][f], normed=True))\n",
    "        \n",
    "        sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Eigendecomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"D\"] = {\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "X[\"D_d\"] = {\"stft\":[], \"logCQT\":[], \"chroma\":[]}\n",
    "\n",
    "kmin = 2\n",
    "kmax = 10\n",
    "\n",
    "for f in range(file_no):\n",
    "    for rep in [\"stft\", \"logCQT\", \"chroma\"]:\n",
    "        #eigendecomposition\n",
    "        evals, evecs = scipy.linalg.eigh(X[\"Lsym\"][rep][f])\n",
    "        #eigenvector filtering\n",
    "        evecs = scipy.ndimage.median_filter(evecs, size=(9, 1))\n",
    "        #normalization\n",
    "        Cnorm = np.cumsum(evecs**2, axis=1)**0.5\n",
    "        #create set of approximations\n",
    "        dist_set = []\n",
    "        for k in range(kmin, kmax):\n",
    "            Xs = evecs[:, :k] / Cnorm[:, k-1:k]\n",
    "            #distance vector to matrix\n",
    "            distance = scipy.spatial.distance.squareform(scipy.spatial.distance.pdist(Xs, metric='euclidean'))\n",
    "            dist_set.append(distance)\n",
    "        X[\"D\"][rep].append(dist_set)\n",
    "\n",
    "        #eigendecomposition\n",
    "        evals, evecs = scipy.linalg.eigh(X[\"Lsym_d\"][rep][f])\n",
    "        #eigenvector filtering\n",
    "        evecs = scipy.ndimage.median_filter(evecs, size=(9, 1))\n",
    "        #normalization\n",
    "        Cnorm = np.cumsum(evecs**2, axis=1)**0.5\n",
    "        #create set of approximations\n",
    "        dist_set = []\n",
    "        for k in range(kmin, kmax):\n",
    "            Xs = evecs[:, :k] / Cnorm[:, k-1:k]\n",
    "            #distance vector to matrix\n",
    "            distance = scipy.spatial.distance.squareform(scipy.spatial.distance.pdist(Xs, metric='euclidean'))\n",
    "            dist_set.append(distance)\n",
    "        X[\"D_d\"][rep].append(dist_set)\n",
    "\n",
    "    sys.stdout.write(\"\\rComputed for %i/%s pieces.\" % ((f+1), str(file_no)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Plotting eigenvector distances"
   ]
  },
  {
   "source": [
    "### >>> STFT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D\"][\"stft\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### >>> logCQT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D\"][\"logCQT\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### >>> Chroma"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D\"][\"chroma\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### >>> STFT Downsampled"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D_d\"][\"stft\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### >>> logCQT Downsampled"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D_d\"][\"logCQT\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "### >>> Chroma Downsampled"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlepad'] = 15\n",
    "plt.set_cmap('magma')\n",
    "fig, ax = plt.subplots(nrows=kmax-kmin, ncols=len(all_names), figsize=(int(3.5*len(all_names)),int(3.7*(kmax-kmin))))\n",
    "for i in range(file_no):\n",
    "    for k in range(kmax-kmin):\n",
    "        ax[k, i].matshow(X[\"D_d\"][\"chroma\"][i][k])\n",
    "        ax[k, i].set(title=(all_names[i])[:-3] + ' ' + str(kmin+k))"
   ]
  },
  {
   "source": [
    "## > Similarity Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### >> Flatten and merge representations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this code cleaner\n",
    "all_flatsets = []\n",
    "for i in range(kmax-kmin):\n",
    "    all_flatsets.append([])\n",
    "    for j in range(all_sets.shape[1]):\n",
    "        all_flatsets[i].append((X[\"D_d\"][\"logCQT\"][i][j])[np.triu_indices(X[\"D_d\"][\"logCQT\"][i][j].shape[0])])\n",
    "all_flatsets = np.asarray(all_flatsets)\n",
    "print(all_flatsets.shape)\n",
    "\n",
    "all_merged = []\n",
    "for i in range(all_flatsets.shape[0]):\n",
    "    all_merged.append(np.empty((0)))\n",
    "    for k in range(kmax-kmin):\n",
    "        all_merged[i] = np.concatenate((all_merged[i], all_flatsets[i][k]))\n",
    "all_merged = np.asarray(all_merged)\n",
    "print(all_merged.shape)"
   ]
  },
  {
   "source": [
    "### >> L1 norm (average of Y1i-Y2i)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_distances = np.zeros((all_merged.shape[0], all_merged.shape[0]))\n",
    "for i in range(all_flatsets.shape[0]):\n",
    "    for j in range(all_flatsets.shape[0]):\n",
    "        L1_distances[i][j] = np.linalg.norm(all_merged[i]-all_merged[j], ord=1)\n",
    "plt.matshow(L1_distances)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### >> L2 norm (average from Y1i-Y2i)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_distances = np.zeros((all_merged.shape[0], all_merged.shape[0]))\n",
    "for i in range(all_flatsets.shape[0]):\n",
    "    for j in range(all_flatsets.shape[0]):\n",
    "        L2_distances[i][j] = np.linalg.norm(all_merged[i]-all_merged[j])\n",
    "plt.matshow(L1_distances)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### >> Directed Hausdorff distance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hausdorff_distances = np.zeros((all_flatsets.shape[0], all_flatsets.shape[0]))\n",
    "for i in range(all_flatsets.shape[0]):\n",
    "    for j in range(all_flatsets.shape[0]):\n",
    "        hausdorff_distances[i][j] = (directed_hausdorff(all_flatsets[i], all_flatsets[j]))[0]\n",
    "plt.matshow(hausdorff_distances)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### >> Minimum distance from Y1i to Y2j for all (i,j)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distances = np.zeros((all_flatsets.shape[0], all_flatsets.shape[0]))\n",
    "for i in range(all_flatsets.shape[0]):\n",
    "    for j in range(all_flatsets.shape[0]):\n",
    "        dists = []\n",
    "        for n in range(kmax-kmin):\n",
    "            for m in range(kmax-kmin):\n",
    "                dists.append(np.linalg.norm(all_merged[i]-all_merged[j]))\n",
    "        min_distances[i][j] = min(dists)\n",
    "plt.matshow(min_distances)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}